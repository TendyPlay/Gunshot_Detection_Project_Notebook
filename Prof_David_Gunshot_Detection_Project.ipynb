{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbSRb8n9zANYTGVzKcT2KT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TendyPlay/Gunshot_Detection_Project_Notebook/blob/main/Prof_David_Gunshot_Detection_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l45YaCehkweh",
        "outputId": "d7848e1f-7830-4ff3-edfa-0f192e584c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Installing PyAudio V0.2.11\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.6).\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 184 kB of archives.\n",
            "After this operation, 891 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudiocpp0 amd64 19.6.0-1 [15.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 portaudio19-dev amd64 19.6.0-1 [104 kB]\n",
            "Fetched 184 kB in 2s (123 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 155569 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyAudio==0.2.11\n",
            "  Downloading PyAudio-0.2.11.tar.gz (37 kB)\n",
            "Building wheels for collected packages: PyAudio\n",
            "  Building wheel for PyAudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyAudio: filename=PyAudio-0.2.11-cp37-cp37m-linux_x86_64.whl size=52607 sha256=383b8f46aa57068e0837547d5527c0e65815b0f07fa18999f482a9e6fa000f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/2e/4c/b71e7e96c861a46e6213bc6bb482b94dcf293a92c5e736c1ec\n",
            "Successfully built PyAudio\n",
            "Installing collected packages: PyAudio\n",
            "Successfully installed PyAudio-0.2.11\n",
            "\n",
            "Installing Schedule V0.6.0\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting schedule==0.6.0\n",
            "  Downloading schedule-0.6.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-0.6.0\n",
            "\n",
            "Installing Librosa V0.4.2\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting librosa==0.4.2\n",
            "  Downloading librosa-0.4.2.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 33.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (4.4.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from librosa==0.4.2) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->librosa==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->librosa==0.4.2) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->librosa==0.4.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->librosa==0.4.2) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->librosa==0.4.2) (4.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.14.0->librosa==0.4.2) (3.1.0)\n",
            "Building wheels for collected packages: librosa\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.4.2-py3-none-any.whl size=1532321 sha256=b48ed74b642081557884a3aac296b976004e65c99946a605620433a27c2b5df7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/ac/68/67b7d126dfdb9064a1a9423754f782a94ec7fa783592fb786c\n",
            "Successfully built librosa\n",
            "Installing collected packages: librosa\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires librosa>=0.7.2, but you have librosa 0.4.2 which is incompatible.\u001b[0m\n",
            "Successfully installed librosa-0.4.2\n",
            "\n",
            "Installing Scipy V1.3.0\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.3.0\n",
            "  Downloading scipy-1.3.0-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy==1.3.0) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 4.1.4 requires scipy>=1.4.1, but you have scipy 1.3.0 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.3.0 which is incompatible.\n",
            "kapre 0.3.7 requires librosa>=0.7.2, but you have librosa 0.4.2 which is incompatible.\n",
            "jaxlib 0.3.15+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.3.0 which is incompatible.\n",
            "jax 0.3.17 requires scipy>=1.5, but you have scipy 1.3.0 which is incompatible.\n",
            "aeppl 0.0.33 requires scipy>=1.4.0, but you have scipy 1.3.0 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.3.0\n",
            "\n",
            "Installing NumPy V1.16.4\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "\n",
            "Installing TendsorFlow V1.14.0\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 48 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.5.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.48.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 70.2 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires librosa>=0.7.2, but you have librosa 0.4.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "\n",
            "Installing Six V1.12.0\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting six==1.12.0\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: six\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "kapre 0.3.7 requires librosa>=0.7.2, but you have librosa 0.4.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "google-api-python-client 1.12.11 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.31.6 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "aeppl 0.0.33 requires scipy>=1.4.0, but you have scipy 1.3.0 which is incompatible.\u001b[0m\n",
            "Successfully installed six-1.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Installing Scikit Learn V0.21.2\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.21.2\n",
            "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2) (1.21.6)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "kapre 0.3.7 requires librosa>=0.7.2, but you have librosa 0.4.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.21.2\n",
            "\n",
            "Installing Python GSM Modem V0.9\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-gsmmodem==0.9\n",
            "  Downloading python-gsmmodem-0.9.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting pyserial>=2.6\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: python-gsmmodem\n",
            "  Building wheel for python-gsmmodem (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-gsmmodem: filename=python_gsmmodem-0.9-py3-none-any.whl size=61421 sha256=6adf1d86f8943282c0f3e4f076d42e7bd611f92f29050d761063d5eeb9ae37c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/5e/54/8f1777455295ccee8d7c8efa771b6007e4b11d105abc4e332f\n",
            "Successfully built python-gsmmodem\n",
            "Installing collected packages: pyserial, python-gsmmodem\n",
            "Successfully installed pyserial-3.5 python-gsmmodem-0.9\n",
            "\n",
            "Installs Done\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:37: UserWarning: Could not import scikits.samplerate. Falling back to scipy.signal\n",
            "  warnings.warn('Could not import scikits.samplerate. '\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  EPS = np.finfo(np.float).eps\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
            "The datapath rcparam was deprecated in Matplotlib 3.2.1 and will be removed two minor releases later.\n",
            "  self[key] = value\n",
            "/usr/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
            "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = value\n",
            "/usr/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
            "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
            "  self[key] = value\n",
            "/usr/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
            "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = value\n",
            "/usr/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
            "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
            "  self[key] = value\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype=np.int):\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
            "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
            "  if self.cachedir is not None:\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nInstalling PyAudio V0.2.11\\n\")\n",
        "\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg #This line and next\n",
        "!pip install PyAudio==0.2.11                                                      #are used to install PyAudio\n",
        "\n",
        "print(\"\\nInstalling Schedule V0.6.0\\n\")\n",
        "\n",
        "!pip install schedule==0.6.0\n",
        "\n",
        "print(\"\\nInstalling Librosa V0.4.2\\n\")\n",
        "\n",
        "!pip install librosa==0.4.2\n",
        "\n",
        "print(\"\\nInstalling Scipy V1.3.0\\n\")\n",
        "\n",
        "!pip install scipy==1.3.0\n",
        "\n",
        "print(\"\\nInstalling NumPy V1.16.4\\n\")\n",
        "\n",
        "!pip install numpy\n",
        "\n",
        "print(\"\\nInstalling TendsorFlow V1.14.0\\n\")\n",
        "\n",
        "!pip install tensorflow==1.14.0\n",
        "\n",
        "print(\"\\nInstalling Six V1.12.0\\n\")\n",
        "\n",
        "!pip install six==1.12.0\n",
        "\n",
        "print(\"\\nInstalling Scikit Learn V0.21.2\\n\")\n",
        "\n",
        "!pip install scikit-learn==0.21.2\n",
        "\n",
        "print(\"\\nInstalling Python GSM Modem V0.9\\n\")\n",
        "\n",
        "!pip install python-gsmmodem==0.9\n",
        "\n",
        "print(\"\\nInstalls Done\\n\")\n",
        "\n",
        "import pyaudio\n",
        "import librosa\n",
        "import logging\n",
        "import time\n",
        "import schedule\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import six\n",
        "import tensorflow.keras as keras\n",
        "from threading import Thread\n",
        "from array import array\n",
        "from datetime import timedelta as td\n",
        "from queue import Queue\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras import backend as K\n",
        "#from gsmmodem.modem import GsmModem Unnecessary as we will not be implementing messaging to celluar just yet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuring the Logger\n",
        "\n",
        "logger = logging.getLogger('debugger')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "ch = logging.FileHandler('output.log')\n",
        "ch.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "xrfq9eGtk1CM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable Initializations\n",
        "\n",
        "AUDIO_FORMAT = pyaudio.paFloat32\n",
        "AUDIO_RATE = 44100\n",
        "NUMBER_OF_AUDIO_CHANNELS = 1\n",
        "AUDIO_DEVICE_INDEX = 6\n",
        "NUMBER_OF_FRAMES_PER_BUFFER = 4410\n",
        "SAMPLE_DURATION = 2\n",
        "AUDIO_VOLUME_THRESHOLD = 0.2\n",
        "NOISE_REDUCTION_ENABLED = False\n",
        "MODEL_CONFIDENCE_THRESHOLD = 0.5\n",
        "MINIMUM_FREQUENCY = 20\n",
        "MAXIMUM_FREQUENCY = AUDIO_RATE // 2\n",
        "NUMBER_OF_MELS = 128\n",
        "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
        "SMS_ALERTS_ENABLED = False\n",
        "ALERT_MESSAGE = \"ALERT: A Gunshot Was Detected on \"\n",
        "NETWORK_COVERAGE_TIMEOUT = 3600\n",
        "DESIGNATED_ALERT_RECIPIENTS = [\"8163449956\", \"9176202840\", \"7857642331\"]\n",
        "SCHEDULED_LOG_FILE_TRUNCATION_TIME = \"00:00\"\n",
        "sound_data = np.zeros(0, dtype = \"float32\")\n",
        "noise_sample_captured = False\n",
        "gunshot_sound_counter = 1\n",
        "noise_sample = []\n",
        "audio_analysis_queue = Queue()\n",
        "sms_alert_queue = Queue()"
      ],
      "metadata": {
        "id": "cE8ie0Efk2Be"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading in Augmented Labels\n",
        "\n",
        "from google.colab import files  #Remove pound symbol if you need to upload augmented_labels.npy, that file can be found here:\n",
        "uploaded = files.upload()       #https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2KI6IH\n",
        "                                 #I suggest saving this file somewhere for future use, as each time you close the session and restart this Notebook,\n",
        "                                 #You will have to reupload the file to run the code.\n",
        "                                 \n",
        "                                 #Left side, click on folder icon, and file will upload to content>augmented_labels.npy\n",
        "                                 #Failure to do this step will cause errors running the Binarizing Labels section and so on\n",
        "\n",
        "labels = np.load(\"/content/augmented_labels.npy\")"
      ],
      "metadata": {
        "id": "OMzmGs0kk3KB",
        "outputId": "27a1f96f-3b31-4add-d919-6ade63ca4f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d7548689-8f81-41d2-a46d-000b8aabd1a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d7548689-8f81-41d2-a46d-000b8aabd1a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1D.tflite to 1D.tflite\n",
            "Saving 128_x_64_2D.tflite to 128_x_64_2D.tflite\n",
            "Saving 128_x_128_2D.tflite to 128_x_128_2D.tflite\n",
            "Saving augmented_labels.npy to augmented_labels.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarizing Labels \n",
        "\n",
        "labels = np.array([(\"gun_shot\" if label == \"gun_shot\" else \"other\") for label in labels])\n",
        "label_binarizer = LabelBinarizer()\n",
        "labels = label_binarizer.fit_transform(labels)\n",
        "labels = np.hstack((labels, 1 - labels))"
      ],
      "metadata": {
        "id": "_eemkVWck465"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Librosa Wrapper Function Definitions\n",
        "\n",
        "def _stft(y, n_fft, hop_length, win_length):\n",
        "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
        "\n",
        "\n",
        "def _istft(y, hop_length, win_length):\n",
        "    return librosa.istft(y, hop_length, win_length)\n",
        "\n",
        "\n",
        "def _amp_to_db(x):\n",
        "    return librosa.core.logamplitude(x, ref_power=1.0, amin=1e-20, top_db=80.0)  # Librosa 0.4.2 functionality\n",
        "\n",
        "\n",
        "def _db_to_amp(x):\n",
        "    return librosa.core.perceptual_weighting(x, frequencies=1.0)  # Librosa 0.4.2 functionality"
      ],
      "metadata": {
        "id": "DVO2_SVbk6N-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Noise Reduction Function Definition\n",
        "\n",
        "def remove_noise(audio_clip,\n",
        "                noise_clip,\n",
        "                n_grad_freq = 2,\n",
        "                n_grad_time = 4,\n",
        "                n_fft = 2048,\n",
        "                win_length = 2048,\n",
        "                hop_length = 512,\n",
        "                n_std_thresh = 1.5,\n",
        "                prop_decrease = 1.0,\n",
        "                verbose = False):\n",
        "    \n",
        "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
        "\n",
        "    Args:\n",
        "        audio_clip (array): The first parameter.\n",
        "        noise_clip (array): The second parameter.\n",
        "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
        "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
        "        n_fft (int): number audio of frames between STFT columns.\n",
        "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
        "        hop_length (int):number audio of frames between STFT columns.\n",
        "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
        "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
        "        verbose: Whether to display time statistics for the noise reduction process\n",
        "\n",
        "    Returns:\n",
        "        array: The recovered signal with noise subtracted\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        start = time.time()\n",
        "        \n",
        "    # Takes a STFT over the noise sample\n",
        "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
        "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
        "    \n",
        "    # Calculates statistics over the noise sample\n",
        "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
        "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
        "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Takes a STFT over the signal sample\n",
        "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
        "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Calculates value to which to mask dB\n",
        "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
        "    \n",
        "    # Creates a smoothing filter for the mask in time and frequency\n",
        "    smoothing_filter = np.outer(\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
        "                np.linspace(1, 0, n_grad_freq + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
        "                np.linspace(1, 0, n_grad_time + 2),\n",
        "            ]\n",
        "        )[1:-1]\n",
        "    )\n",
        "    \n",
        "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
        "    \n",
        "    # Calculates the threshold for each frequency/time bin\n",
        "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
        "                          np.shape(sig_stft_db)[1],\n",
        "                          axis = 0).T\n",
        "    \n",
        "    # Masks segment if the signal is above the threshold\n",
        "    sig_mask = sig_stft_db < db_thresh\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Masking:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Convolves the mask with a smoothing filter\n",
        "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
        "    sig_mask = sig_mask * prop_decrease\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Mask convolution:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Masks the signal\n",
        "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
        "                          + np.ones(np.shape(mask_gain_dB))\n",
        "                          * mask_gain_dB * sig_mask)  # Masks real\n",
        "    \n",
        "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
        "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Mask application:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Recovers the signal\n",
        "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
        "    recovered_spec = _amp_to_db(\n",
        "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
        "    )\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Signal recovery:\", td(seconds = time.time() - start))\n",
        "        \n",
        "    # Returns noise-reduced audio sample\n",
        "    return recovered_signal\n"
      ],
      "metadata": {
        "id": "ex4Z14U7k7dK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 1D Sound Arrays into Spectrograms #\n",
        "\n",
        "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
        "    S = np.asarray(S)\n",
        "    if amin <= 0:\n",
        "        logger.debug(\"ParameterError: amin must be strictly positive\")\n",
        "    if np.issubdtype(S.dtype, np.complexfloating):\n",
        "        logger.debug(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
        "        magnitude = np.abs(S)\n",
        "    else:\n",
        "        magnitude = S\n",
        "    if six.callable(ref):\n",
        "        # User supplied a function to calculate reference power\n",
        "        ref_value = ref(magnitude)\n",
        "    else:\n",
        "        ref_value = np.abs(ref)\n",
        "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
        "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
        "    if top_db is not None:\n",
        "        if top_db < 0:\n",
        "            logger.debug(\"ParameterError: top_db must be non-negative\")\n",
        "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
        "    return log_spec\n",
        "\n",
        "\n",
        "def convert_audio_to_spectrogram(data):\n",
        "    spectrogram = librosa.feature.melspectrogram(y=data, sr=AUDIO_RATE,\n",
        "                                                 hop_length=HOP_LENGTH,\n",
        "                                                 fmin=MINIMUM_FREQUENCY,\n",
        "                                                 fmax=MAXIMUM_FREQUENCY,\n",
        "                                                 n_mels=NUMBER_OF_MELS,\n",
        "                                                 n_fft=NUMBER_OF_FFTS)\n",
        "    spectrogram = power_to_db(spectrogram)\n",
        "    spectrogram = spectrogram.astype(np.float32)\n",
        "    return spectrogram"
      ],
      "metadata": {
        "id": "3fqf_zvAk9IT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wav File Composition Function\n",
        "\n",
        "# Saves a two-second gunshot sample as a WAV file\n",
        "def create_gunshot_wav_file(microphone_data, index, timestamp):\n",
        "    librosa.output.write_wav(\"~/Gunshot Detection System Recordings/Gunshot Sound Sample #\"\n",
        "                            + str(index) + \" (\"\n",
        "                            + str(timestamp) + \").wav\", microphone_data, 22050)"
      ],
      "metadata": {
        "id": "m6_kf0Fhk-X-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log File Truncation Function\n",
        "\n",
        "def clear_log_file():\n",
        "    with open(\"output.log\", 'w'):\n",
        "        pass"
      ],
      "metadata": {
        "id": "eblI7T6zk_fG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Models\n",
        "\n",
        "#from google.colab import files  #Again, must go to: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2KI6IH\n",
        "#uploaded = files.upload()       #And upload the following Files:\n",
        "                                 #1D.tflite\n",
        "                                 #128_x_64_2D.tflite\n",
        "                                 #128_x_128_2D.tflite\n",
        "\n",
        "\n",
        "# Loads 44100 x 1 Keras model from H5 file\n",
        "interpreter_1 = tf.lite.Interpreter(model_path = \"/content/1D.tflite\")\n",
        "interpreter_1.allocate_tensors()\n",
        "    \n",
        "# Sets the input shape for the 44100 x 1 model\n",
        "input_details_1 = interpreter_1.get_input_details()\n",
        "output_details_1 = interpreter_1.get_output_details()\n",
        "input_shape_1 = input_details_1[0]['shape']\n",
        "\n",
        "# Loads 128 x 64 Keras model from H5 file\n",
        "interpreter_2 = tf.lite.Interpreter(model_path = \"/content/128_x_64_2D.tflite\")\n",
        "interpreter_2.allocate_tensors()\n",
        "\n",
        "# Gets the input shape from the 128 x 64 Keras model\n",
        "input_details_2 = interpreter_2.get_input_details()\n",
        "output_details_2 = interpreter_2.get_output_details()\n",
        "input_shape_2 = input_details_2[0]['shape']\n",
        "\n",
        "# Loads 128 x 128 Keras model from H5 file\n",
        "interpreter_3 = tf.lite.Interpreter(model_path = \"/content/128_x_128_2D.tflite\")\n",
        "interpreter_3.allocate_tensors()\n",
        "\n",
        "# Gets the input shape from the 128 x 128 Keras model\n",
        "input_details_3 = interpreter_3.get_input_details()\n",
        "output_details_3 = interpreter_3.get_output_details()\n",
        "input_shape_3 = input_details_3[0]['shape']"
      ],
      "metadata": {
        "id": "8BV3UV8jlAX9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMS Alert Thread\n",
        "\n",
        "# The SMS alert thread will run indefinitely\n",
        "def send_sms_alert():\n",
        "    \n",
        "    if SMS_ALERTS_ENABLED:\n",
        "        \n",
        "        # Configuring the Modem Connection\n",
        "        modem_port = '/dev/ttyUSB0'\n",
        "        modem_baudrate = 115200\n",
        "        modem_sim_pin = None  # SIM card PIN (if any)\n",
        "    \n",
        "        # Establishing a Connection to the SMS Modem\n",
        "        logger.debug(\"Initializing connection to modem...\")\n",
        "        modem = GsmModem(modem_port, modem_baudrate)\n",
        "        modem.smsTextMode = False\n",
        "        \n",
        "        if modem_sim_pin:\n",
        "            modem.connect(modem_sim_pin)\n",
        "        else:\n",
        "            modem.connect()\n",
        "    \n",
        "        # Continuously dispatches SMS alerts to a list of designated recipients\n",
        "        while True:\n",
        "            sms_alert_status = sms_alert_queue.get()\n",
        "            sms_alert_timestamp = sms_alert_queue.get()\n",
        "            if sms_alert_status == \"Gunshot Detected\":\n",
        "                try:\n",
        "                    # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
        "                    modem.waitForNetworkCoverage(timeout = NETWORK_COVERAGE_TIMEOUT)\n",
        "                    for number in DESIGNATED_ALERT_RECIPIENTS:\n",
        "                        modem.sendSms(number, ALERT_MESSAGE + sms_alert_timestamp)\n",
        "                    logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
        "                except:\n",
        "                    logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
        "                    pass\n",
        "                finally:\n",
        "                    logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
        "    \n",
        "    else:\n",
        "        while True:\n",
        "            sms_alert_status = sms_alert_queue.get()\n",
        "            sms_alert_timestamp = sms_alert_queue.get()\n",
        "            if sms_alert_status == \"Gunshot Detected\":\n",
        "                logger.debug(ALERT_MESSAGE + sms_alert_timestamp)\n",
        "\n",
        "\n",
        "# Starts the SMS alert thread\n",
        "sms_alert_thread = Thread(target = send_sms_alert)\n",
        "sms_alert_thread.start()"
      ],
      "metadata": {
        "id": "tvWICx7PlBqj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback Thread\n",
        "\n",
        "def callback(in_data, frame_count, time_info, status):\n",
        "    global sound_data\n",
        "    sound_buffer = np.frombuffer(in_data, dtype = \"float32\")\n",
        "    sound_data = np.append(sound_data, sound_buffer)\n",
        "    if len(sound_data) >= 88200:\n",
        "        audio_analysis_queue.put(sound_data)\n",
        "        current_time = time.ctime(time.time())\n",
        "        audio_analysis_queue.put(current_time)\n",
        "        sound_data = np.zeros(0, dtype = \"float32\")\n",
        "    return sound_buffer, pyaudio.paContinue\n",
        "\n",
        "pa = pyaudio.PyAudio()\n",
        "\n",
        "#stream = pa.open(format = AUDIO_FORMAT,                #As soon as you try and run this line, it will crash the runtime\n",
        "                #rate = AUDIO_RATE,\n",
        "                 #channels = NUMBER_OF_AUDIO_CHANNELS,\n",
        "                 #input_device_index = AUDIO_DEVICE_INDEX,\n",
        "                 #frames_per_buffer = NUMBER_OF_FRAMES_PER_BUFFER,\n",
        "                 #input = True,\n",
        "                 #stream_callback = callback)\n",
        "\n",
        "# Starts the callback thread\n",
        "#stream.start_stream()\n",
        "#logger.debug(\"--- Listening to Audio Stream ---\")"
      ],
      "metadata": {
        "id": "yfvU_YsRlD8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Audio Analysis Thread\n",
        "\n",
        "# Starts the scheduler for clearing the primary log file\n",
        "schedule.every().day.at(SCHEDULED_LOG_FILE_TRUNCATION_TIME).do(clear_log_file)\n",
        "\n",
        "# This thread will run indefinitely\n",
        "while True:\n",
        "    # Refreshes the scheduler\n",
        "    schedule.run_pending()\n",
        "    \n",
        "    # Gets a sample and its timestamp from the audio analysis queue\n",
        "    microphone_data = np.array(audio_analysis_queue.get(), dtype = \"float32\")\n",
        "    time_of_sample_occurrence = audio_analysis_queue.get()\n",
        "    \n",
        "    # Cleans up the global NumPy audio data source\n",
        "    sound_data = np.zeros(0, dtype = \"float32\")\n",
        "        \n",
        "    # Finds the current sample's maximum frequency value\n",
        "    maximum_frequency_value = np.max(microphone_data)\n",
        "        \n",
        "    # Determines whether a given sample potentially contains a gunshot\n",
        "    if maximum_frequency_value >= AUDIO_VOLUME_THRESHOLD:\n",
        "        \n",
        "        # Displays the current sample's maximum frequency value\n",
        "        logger.debug(\"The maximum frequency value of a given sample before processing: \" + str(maximum_frequency_value))\n",
        "        \n",
        "        # Post-processes the microphone data\n",
        "        modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = AUDIO_RATE, target_sr = 22050)\n",
        "        if NOISE_REDUCTION_ENABLED and noise_sample_captured:\n",
        "                # Acts as a substitute for normalization\n",
        "                modified_microphone_data = remove_noise(audio_clip = modified_microphone_data, noise_clip = noise_sample)\n",
        "                number_of_missing_hertz = 44100 - len(modified_microphone_data)\n",
        "                modified_microphone_data = np.array(modified_microphone_data.tolist() + [0 for i in range(number_of_missing_hertz)], dtype = \"float32\")\n",
        "        modified_microphone_data = modified_microphone_data[:44100]\n",
        "\n",
        "        # Passes an audio sample of an appropriate format into the model for inference\n",
        "        processed_data_1 = modified_microphone_data\n",
        "        processed_data_1 = processed_data_1.reshape(input_shape_1)\n",
        "\n",
        "        HOP_LENGTH = 345 * 2\n",
        "        processed_data_2 = convert_audio_to_spectrogram(data = modified_microphone_data)\n",
        "        processed_data_2 = processed_data_2.reshape(input_shape_2)\n",
        "            \n",
        "        HOP_LENGTH = 345\n",
        "        processed_data_3 = convert_audio_to_spectrogram(data = modified_microphone_data)\n",
        "        processed_data_3 = processed_data_3.reshape(input_shape_3)\n",
        "\n",
        "        # Performs inference with the instantiated TensorFlow Lite models\n",
        "        interpreter_1.set_tensor(input_details_1[0]['index'], processed_data_1)\n",
        "        interpreter_1.invoke()\n",
        "        probabilities_1 = interpreter_1.get_tensor(output_details_1[0]['index'])\n",
        "        \n",
        "        interpreter_2.set_tensor(input_details_2[0]['index'], processed_data_2)\n",
        "        interpreter_2.invoke()\n",
        "        probabilities_2 = interpreter_2.get_tensor(output_details_2[0]['index'])\n",
        "        \n",
        "        interpreter_3.set_tensor(input_details_3[0]['index'], processed_data_3)\n",
        "        interpreter_3.invoke()\n",
        "        probabilities_3 = interpreter_3.get_tensor(output_details_3[0]['index'])\n",
        "        \n",
        "        logger.debug(\"The 44100 x 1 model-predicted probability values: \" + str(probabilities_1[0]))\n",
        "        logger.debug(\"The 128 x 64 model-predicted probability values: \" + str(probabilities_2[0]))\n",
        "        logger.debug(\"The 128 x 128 model-predicted probability values: \" + str(probabilities_3[0]))\n",
        "        logger.debug(\"The 44100 x 1 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_1[:, 0])[0])\n",
        "        logger.debug(\"The 128 x 64 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_2[:, 0])[0])\n",
        "        logger.debug(\"The 128 x 128 model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities_3[:, 0])[0])\n",
        "        \n",
        "        # Records which models, if any, identified a gunshot\n",
        "        model_1_activated = probabilities_1[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
        "        model_2_activated = probabilities_2[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
        "        model_3_activated = probabilities_3[0][1] >= MODEL_CONFIDENCE_THRESHOLD\n",
        "\n",
        "        # Majority Rules: Determines if a gunshot sound was detected by a majority of the models\n",
        "        if model_1_activated and model_2_activated or model_2_activated and model_3_activated or model_1_activated and model_3_activated:\n",
        "                \n",
        "            # Sends out an SMS alert\n",
        "            sms_alert_queue.put(\"Gunshot Detected\")\n",
        "\n",
        "            # Sends out the time a given sample was heard\n",
        "            sms_alert_queue.put(time_of_sample_occurrence)\n",
        "\n",
        "            # Makes a WAV file of the gunshot sample\n",
        "            create_gunshot_wav_file(modified_microphone_data, gunshot_sound_counter, time_of_sample_occurrence)\n",
        "\n",
        "            # Increments the counter for gunshot sound file names\n",
        "            gunshot_sound_counter += 1\n",
        "    \n",
        "    # Allows us to capture two seconds of background noise from the microphone for noise reduction\n",
        "    elif NOISE_REDUCTION_ENABLED and not noise_sample_captured:\n",
        "        noise_sample = librosa.resample(y = microphone_data, orig_sr = AUDIO_RATE, target_sr = 22050)\n",
        "        noise_sample = noise_sample[:44100]\n",
        "        noise_sample_captured = True"
      ],
      "metadata": {
        "id": "S2eavxLhqC1D",
        "outputId": "66f3c5e0-7baa-41a6-ae78-db3ad384cb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f28cce5c3f5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Gets a sample and its timestamp from the audio analysis queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmicrophone_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_analysis_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtime_of_sample_occurrence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_analysis_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}