{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1mfAeZV1Zv27sTXbokDzE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TendyPlay/Gunshot_Detection_Project_Notebook/blob/main/Prof_David_Gunshot_Detection_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l45YaCehkweh"
      },
      "outputs": [],
      "source": [
        "print(\"\\nInstalling PyAudio V0.2.11\\n\")\n",
        "\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg #This line and next\n",
        "!pip install PyAudio==0.2.11                                                      #are used to install PyAudio\n",
        "\n",
        "print(\"\\nInstalling Schedule V0.6.0\\n\")\n",
        "\n",
        "!pip install schedule==0.6.0\n",
        "\n",
        "print(\"\\nInstalling Librosa V0.4.2\\n\")\n",
        "\n",
        "!pip install librosa==0.4.2\n",
        "\n",
        "print(\"\\nInstalling Scipy V1.3.0\\n\")\n",
        "\n",
        "!pip install scipy==1.3.0\n",
        "\n",
        "print(\"\\nInstalling NumPy V1.16.4\\n\")\n",
        "\n",
        "!pip install numpy\n",
        "\n",
        "print(\"\\nInstalling TendsorFlow V1.14.0\\n\")\n",
        "\n",
        "!pip install tensorflow==1.14.0\n",
        "\n",
        "print(\"\\nInstalling Six V1.12.0\\n\")\n",
        "\n",
        "!pip install six==1.12.0\n",
        "\n",
        "print(\"\\nInstalling Scikit Learn V0.21.2\\n\")\n",
        "\n",
        "!pip install scikit-learn==0.21.2\n",
        "\n",
        "print(\"\\nInstalling Python GSM Modem V0.9\\n\")\n",
        "\n",
        "!pip install python-gsmmodem==0.9\n",
        "\n",
        "print(\"\\nInstalls Done\\n\")\n",
        "\n",
        "import pyaudio\n",
        "import librosa\n",
        "import logging\n",
        "import time\n",
        "import schedule\n",
        "import scipy.signal\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import six\n",
        "import tensorflow.keras as keras\n",
        "from threading import Thread\n",
        "from array import array\n",
        "from datetime import timedelta as td\n",
        "from queue import Queue\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras import backend as K\n",
        "#from gsmmodem.modem import GsmModem Unnecessary as we will not be implementing messaging to celluar just yet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuring the Logger\n",
        "\n",
        "logger = logging.getLogger('debugger')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "ch = logging.FileHandler('output.log')\n",
        "ch.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "xrfq9eGtk1CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable Initializations\n",
        "\n",
        "AUDIO_FORMAT = pyaudio.paFloat32\n",
        "AUDIO_RATE = 44100\n",
        "NUMBER_OF_AUDIO_CHANNELS = 1\n",
        "AUDIO_DEVICE_INDEX = 6\n",
        "NUMBER_OF_FRAMES_PER_BUFFER = 4410\n",
        "SAMPLE_DURATION = 2\n",
        "AUDIO_VOLUME_THRESHOLD = 0.2\n",
        "NOISE_REDUCTION_ENABLED = False\n",
        "MODEL_CONFIDENCE_THRESHOLD = 0.5\n",
        "MINIMUM_FREQUENCY = 20\n",
        "MAXIMUM_FREQUENCY = AUDIO_RATE // 2\n",
        "NUMBER_OF_MELS = 128\n",
        "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
        "SMS_ALERTS_ENABLED = False\n",
        "ALERT_MESSAGE = \"ALERT: A Gunshot Was Detected on \"\n",
        "NETWORK_COVERAGE_TIMEOUT = 3600\n",
        "DESIGNATED_ALERT_RECIPIENTS = [\"8163449956\", \"9176202840\", \"7857642331\"]\n",
        "SCHEDULED_LOG_FILE_TRUNCATION_TIME = \"00:00\"\n",
        "sound_data = np.zeros(0, dtype = \"float32\")\n",
        "noise_sample_captured = False\n",
        "gunshot_sound_counter = 1\n",
        "noise_sample = []\n",
        "audio_analysis_queue = Queue()\n",
        "sms_alert_queue = Queue()"
      ],
      "metadata": {
        "id": "cE8ie0Efk2Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading in Augmented Labels\n",
        "\n",
        "#from google.colab import files  #Remove pound symbol if you need to upload augmented_labels.npy, that file can be found here:\n",
        "#uploaded = files.upload()       #https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2KI6IH\n",
        "                                 #I suggest saving this file somewhere for future use, as each time you close the session and restart this Notebook,\n",
        "                                 #You will have to reupload the file to run the code.\n",
        "                                 \n",
        "                                 #Left side, click on folder icon, and file will upload to content>augmented_labels.npy\n",
        "                                 #Failure to do this step will cause errors running the Binarizing Labels section and so on\n",
        "\n",
        "labels = np.load(\"/content/augmented_labels.npy\")"
      ],
      "metadata": {
        "id": "OMzmGs0kk3KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarizing Labels \n",
        "\n",
        "labels = np.array([(\"gun_shot\" if label == \"gun_shot\" else \"other\") for label in labels])\n",
        "label_binarizer = LabelBinarizer()\n",
        "labels = label_binarizer.fit_transform(labels)\n",
        "labels = np.hstack((labels, 1 - labels))"
      ],
      "metadata": {
        "id": "_eemkVWck465"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Librosa Wrapper Function Definitions\n",
        "\n",
        "def _stft(y, n_fft, hop_length, win_length):\n",
        "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
        "\n",
        "\n",
        "def _istft(y, hop_length, win_length):\n",
        "    return librosa.istft(y, hop_length, win_length)\n",
        "\n",
        "\n",
        "def _amp_to_db(x):\n",
        "    return librosa.core.logamplitude(x, ref_power=1.0, amin=1e-20, top_db=80.0)  # Librosa 0.4.2 functionality\n",
        "\n",
        "\n",
        "def _db_to_amp(x):\n",
        "    return librosa.core.perceptual_weighting(x, frequencies=1.0)  # Librosa 0.4.2 functionality"
      ],
      "metadata": {
        "id": "DVO2_SVbk6N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Noise Reduction Function Definition\n",
        "\n",
        "def remove_noise(audio_clip,\n",
        "                noise_clip,\n",
        "                n_grad_freq = 2,\n",
        "                n_grad_time = 4,\n",
        "                n_fft = 2048,\n",
        "                win_length = 2048,\n",
        "                hop_length = 512,\n",
        "                n_std_thresh = 1.5,\n",
        "                prop_decrease = 1.0,\n",
        "                verbose = False):\n",
        "    \n",
        "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
        "\n",
        "    Args:\n",
        "        audio_clip (array): The first parameter.\n",
        "        noise_clip (array): The second parameter.\n",
        "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
        "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
        "        n_fft (int): number audio of frames between STFT columns.\n",
        "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
        "        hop_length (int):number audio of frames between STFT columns.\n",
        "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
        "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
        "        verbose: Whether to display time statistics for the noise reduction process\n",
        "\n",
        "    Returns:\n",
        "        array: The recovered signal with noise subtracted\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        start = time.time()\n",
        "        \n",
        "    # Takes a STFT over the noise sample\n",
        "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
        "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
        "    \n",
        "    # Calculates statistics over the noise sample\n",
        "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
        "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
        "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Takes a STFT over the signal sample\n",
        "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
        "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Calculates value to which to mask dB\n",
        "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
        "    \n",
        "    # Creates a smoothing filter for the mask in time and frequency\n",
        "    smoothing_filter = np.outer(\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
        "                np.linspace(1, 0, n_grad_freq + 2),\n",
        "            ]\n",
        "        )[1:-1],\n",
        "        np.concatenate(\n",
        "            [\n",
        "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
        "                np.linspace(1, 0, n_grad_time + 2),\n",
        "            ]\n",
        "        )[1:-1]\n",
        "    )\n",
        "    \n",
        "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
        "    \n",
        "    # Calculates the threshold for each frequency/time bin\n",
        "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
        "                          np.shape(sig_stft_db)[1],\n",
        "                          axis = 0).T\n",
        "    \n",
        "    # Masks segment if the signal is above the threshold\n",
        "    sig_mask = sig_stft_db < db_thresh\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Masking:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Convolves the mask with a smoothing filter\n",
        "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
        "    sig_mask = sig_mask * prop_decrease\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Mask convolution:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Masks the signal\n",
        "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
        "                          + np.ones(np.shape(mask_gain_dB))\n",
        "                          * mask_gain_dB * sig_mask)  # Masks real\n",
        "    \n",
        "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
        "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Mask application:\", td(seconds = time.time() - start))\n",
        "        start = time.time()\n",
        "        \n",
        "    # Recovers the signal\n",
        "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
        "    recovered_spec = _amp_to_db(\n",
        "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
        "    )\n",
        "    \n",
        "    # Debugging\n",
        "    if verbose:\n",
        "        print(\"Signal recovery:\", td(seconds = time.time() - start))\n",
        "        \n",
        "    # Returns noise-reduced audio sample\n",
        "    return recovered_signal\n"
      ],
      "metadata": {
        "id": "ex4Z14U7k7dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 1D Sound Arrays into Spectrograms #\n",
        "\n",
        "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
        "    S = np.asarray(S)\n",
        "    if amin <= 0:\n",
        "        logger.debug(\"ParameterError: amin must be strictly positive\")\n",
        "    if np.issubdtype(S.dtype, np.complexfloating):\n",
        "        logger.debug(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
        "        magnitude = np.abs(S)\n",
        "    else:\n",
        "        magnitude = S\n",
        "    if six.callable(ref):\n",
        "        # User supplied a function to calculate reference power\n",
        "        ref_value = ref(magnitude)\n",
        "    else:\n",
        "        ref_value = np.abs(ref)\n",
        "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
        "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
        "    if top_db is not None:\n",
        "        if top_db < 0:\n",
        "            logger.debug(\"ParameterError: top_db must be non-negative\")\n",
        "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
        "    return log_spec\n",
        "\n",
        "\n",
        "def convert_audio_to_spectrogram(data):\n",
        "    spectrogram = librosa.feature.melspectrogram(y=data, sr=AUDIO_RATE,\n",
        "                                                 hop_length=HOP_LENGTH,\n",
        "                                                 fmin=MINIMUM_FREQUENCY,\n",
        "                                                 fmax=MAXIMUM_FREQUENCY,\n",
        "                                                 n_mels=NUMBER_OF_MELS,\n",
        "                                                 n_fft=NUMBER_OF_FFTS)\n",
        "    spectrogram = power_to_db(spectrogram)\n",
        "    spectrogram = spectrogram.astype(np.float32)\n",
        "    return spectrogram"
      ],
      "metadata": {
        "id": "3fqf_zvAk9IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wav File Composition Function\n",
        "\n",
        "# Saves a two-second gunshot sample as a WAV file\n",
        "def create_gunshot_wav_file(microphone_data, index, timestamp):\n",
        "    librosa.output.write_wav(\"~/Gunshot Detection System Recordings/Gunshot Sound Sample #\"\n",
        "                            + str(index) + \" (\"\n",
        "                            + str(timestamp) + \").wav\", microphone_data, 22050)"
      ],
      "metadata": {
        "id": "m6_kf0Fhk-X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log File Truncation Function\n",
        "\n",
        "def clear_log_file():\n",
        "    with open(\"output.log\", 'w'):\n",
        "        pass"
      ],
      "metadata": {
        "id": "eblI7T6zk_fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Models\n",
        "\n",
        "#from google.colab import files  #Again, must go to: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2KI6IH\n",
        "#uploaded = files.upload()       #And upload the following Files:\n",
        "                                 #1D.tflite\n",
        "                                 #128_x_64_2D.tflite\n",
        "                                 #128_x_128_2D.tflite\n",
        "\n",
        "\n",
        "# Loads 44100 x 1 Keras model from H5 file\n",
        "interpreter_1 = tf.lite.Interpreter(model_path = \"/content/1D.tflite\")\n",
        "interpreter_1.allocate_tensors()\n",
        "    \n",
        "# Sets the input shape for the 44100 x 1 model\n",
        "input_details_1 = interpreter_1.get_input_details()\n",
        "output_details_1 = interpreter_1.get_output_details()\n",
        "input_shape_1 = input_details_1[0]['shape']\n",
        "\n",
        "# Loads 128 x 64 Keras model from H5 file\n",
        "interpreter_2 = tf.lite.Interpreter(model_path = \"/content/128_x_64_2D.tflite\")\n",
        "interpreter_2.allocate_tensors()\n",
        "\n",
        "# Gets the input shape from the 128 x 64 Keras model\n",
        "input_details_2 = interpreter_2.get_input_details()\n",
        "output_details_2 = interpreter_2.get_output_details()\n",
        "input_shape_2 = input_details_2[0]['shape']\n",
        "\n",
        "# Loads 128 x 128 Keras model from H5 file\n",
        "interpreter_3 = tf.lite.Interpreter(model_path = \"/content/128_x_128_2D.tflite\")\n",
        "interpreter_3.allocate_tensors()\n",
        "\n",
        "# Gets the input shape from the 128 x 128 Keras model\n",
        "input_details_3 = interpreter_3.get_input_details()\n",
        "output_details_3 = interpreter_3.get_output_details()\n",
        "input_shape_3 = input_details_3[0]['shape']"
      ],
      "metadata": {
        "id": "8BV3UV8jlAX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMS Alert Thread\n",
        "\n",
        "# The SMS alert thread will run indefinitely\n",
        "def send_sms_alert():\n",
        "    \n",
        "    if SMS_ALERTS_ENABLED:\n",
        "        \n",
        "        # Configuring the Modem Connection\n",
        "        modem_port = '/dev/ttyUSB0'\n",
        "        modem_baudrate = 115200\n",
        "        modem_sim_pin = None  # SIM card PIN (if any)\n",
        "    \n",
        "        # Establishing a Connection to the SMS Modem\n",
        "        logger.debug(\"Initializing connection to modem...\")\n",
        "        modem = GsmModem(modem_port, modem_baudrate)\n",
        "        modem.smsTextMode = False\n",
        "        \n",
        "        if modem_sim_pin:\n",
        "            modem.connect(modem_sim_pin)\n",
        "        else:\n",
        "            modem.connect()\n",
        "    \n",
        "        # Continuously dispatches SMS alerts to a list of designated recipients\n",
        "        while True:\n",
        "            sms_alert_status = sms_alert_queue.get()\n",
        "            sms_alert_timestamp = sms_alert_queue.get()\n",
        "            if sms_alert_status == \"Gunshot Detected\":\n",
        "                try:\n",
        "                    # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
        "                    modem.waitForNetworkCoverage(timeout = NETWORK_COVERAGE_TIMEOUT)\n",
        "                    for number in DESIGNATED_ALERT_RECIPIENTS:\n",
        "                        modem.sendSms(number, ALERT_MESSAGE + sms_alert_timestamp)\n",
        "                    logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
        "                except:\n",
        "                    logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
        "                    pass\n",
        "                finally:\n",
        "                    logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
        "    \n",
        "    else:\n",
        "        while True:\n",
        "            sms_alert_status = sms_alert_queue.get()\n",
        "            sms_alert_timestamp = sms_alert_queue.get()\n",
        "            if sms_alert_status == \"Gunshot Detected\":\n",
        "                logger.debug(ALERT_MESSAGE + sms_alert_timestamp)\n",
        "\n",
        "\n",
        "# Starts the SMS alert thread\n",
        "sms_alert_thread = Thread(target = send_sms_alert)\n",
        "sms_alert_thread.start()"
      ],
      "metadata": {
        "id": "tvWICx7PlBqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback Thread\n",
        "\n",
        "def callback(in_data, frame_count, time_info, status):\n",
        "    global sound_data\n",
        "    sound_buffer = np.frombuffer(in_data, dtype = \"float32\")\n",
        "    sound_data = np.append(sound_data, sound_buffer)\n",
        "    if len(sound_data) >= 88200:\n",
        "        audio_analysis_queue.put(sound_data)\n",
        "        current_time = time.ctime(time.time())\n",
        "        audio_analysis_queue.put(current_time)\n",
        "        sound_data = np.zeros(0, dtype = \"float32\")\n",
        "    return sound_buffer, pyaudio.paContinue\n",
        "\n",
        "pa = pyaudio.PyAudio()\n",
        "\n",
        "#stream = pa.open(format = AUDIO_FORMAT,\n",
        "                #rate = AUDIO_RATE,\n",
        "                 #channels = NUMBER_OF_AUDIO_CHANNELS,\n",
        "                 #input_device_index = AUDIO_DEVICE_INDEX,\n",
        "                 #frames_per_buffer = NUMBER_OF_FRAMES_PER_BUFFER,\n",
        "                 #input = True,\n",
        "                 #stream_callback = callback)\n",
        "\n",
        "# Starts the callback thread\n",
        "##stream.start_stream()\n",
        "##logger.debug(\"--- Listening to Audio Stream ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "yfvU_YsRlD8G",
        "outputId": "c987c3dd-88a2-4984-89bd-aad8c7a81a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cc8f9fa45996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msound_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaContinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#stream = pa.open(format = AUDIO_FORMAT,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pyaudio' is not defined"
          ]
        }
      ]
    }
  ]
}